{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# functions\n",
    "def most_frequent(List):\n",
    "    counter = 0\n",
    "    num = List[0]\n",
    "     \n",
    "    for i in List:\n",
    "        curr_frequency = List.count(i)\n",
    "        if(curr_frequency> counter):\n",
    "            counter = curr_frequency\n",
    "            num = i\n",
    " \n",
    "    return num\n",
    "def selectOccupations(df, columnName):\n",
    "    \"\"\"\n",
    "    UK wage data is provided as a CSV where the occupation is provided with increasing granularity (e.g. managers > managers in transport > managers in transport and distribution)\n",
    "    I only want to store the most granular occupations with wage data so that involves only selecting the categories with the most tabs.\n",
    "    This should return a DataFrame that has only the more granular occupations WITH mean | median salary data.\n",
    "    \"\"\"\n",
    "    diff = []\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        A = df.loc[i, columnName].split(\" \")\n",
    "        B = df.loc[i, columnName].strip().split(\" \")\n",
    "        df.loc[i, columnName] = df.loc[i, columnName].strip()\n",
    "        diff.append(len(A)-len(B))\n",
    "\n",
    "    most_freq = most_frequent(diff) # we are selecting the most frequent difference instead of the maximum difference after a peek at the data shows some random outliers that might just be entry error\n",
    "\n",
    "    # create columns to base selections for df\n",
    "    df[\"diff\"] = diff\n",
    "    df['medianSeries'] = pd.to_numeric(df.Median, errors='coerce').notnull()\n",
    "    df['meanSeries'] = pd.to_numeric(df.Mean, errors='coerce').notnull()\n",
    "    df = df[(df[\"medianSeries\"] | df[\"meanSeries\"]) & (df[\"diff\"]==most_freq)].reset_index(drop=True)\n",
    "    df = df.replace('x', np.NaN)\n",
    "    return df.iloc[:,0:4]\n",
    "def jsonifyOccupations(df, yearInput):\n",
    "    \"\"\"\n",
    "    Given a dataframe of occupations with mean | median salary data for a given year, write a json string with the following format:\n",
    "    Yeah, there's probably a way to do this with a pandas grouping or pivot but I hate pandas.\n",
    "    {\n",
    "        'jobA': {\n",
    "            'year_1': {\n",
    "                'median': 0000000,\n",
    "                'mean': 0000000\n",
    "            }\n",
    "        },\n",
    "        \n",
    "        'jobB': {\n",
    "            'year_1': {\n",
    "                'median': 0000000,\n",
    "                'mean': 0000000\n",
    "            }\n",
    "        },\n",
    "        ...\n",
    "        \n",
    "        'jobZ': {\n",
    "            'year_1': {\n",
    "                'median': 0000000,\n",
    "                'mean': 0000000\n",
    "            }\n",
    "        },\n",
    "        \n",
    "    }\n",
    "    \"\"\"\n",
    "    d = {}\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        content = dict.fromkeys(['median', 'mean'])\n",
    "        content['median'] = df.loc[i,'Median']\n",
    "        content['mean'] = df.loc[i,'Mean']\n",
    "        year = {str(yearInput): content}\n",
    "        d[df.loc[i,'Description']] = [year]\n",
    "    return d\n",
    "def merge_dictionaries(dictA, dictB):\n",
    "    \"\"\"\n",
    "    Bruh does this function already exist wtf. This sounds like a homework problem but anyway\n",
    "    Take dictB. \n",
    "    If a key in dictB is present in dictA, append the contents of the key to dictA[key].\n",
    "    Otherwise, add dictB[key] and it's contents as a new key in dictA.\n",
    "    \"\"\"\n",
    "    for key in dictB:\n",
    "        if key in dictA.keys():\n",
    "            dictA[key].append(dictB[key][0])\n",
    "        else:\n",
    "            dictA[key] = dictB[key]\n",
    "    return dictA\n",
    "\n",
    "# calls\n",
    "UK2017 = jsonifyOccupations(selectOccupations(pd.read_csv(\"raw data/UK 2017.csv\"), \"Description\"), 2017)\n",
    "UK2018 = jsonifyOccupations(selectOccupations(pd.read_csv(\"raw data/UK 2018.csv\"), \"Description\"), 2018)\n",
    "UK2019 = jsonifyOccupations(selectOccupations(pd.read_csv(\"raw data/UK 2019.csv\"), \"Description\"), 2019)\n",
    "UK2020 = jsonifyOccupations(selectOccupations(pd.read_csv(\"raw data/UK 2020.csv\"), \"Description\"), 2020)\n",
    "UK2021 = jsonifyOccupations(selectOccupations(pd.read_csv(\"raw data/UK 2021.csv\"), \"Description\"), 2021)\n",
    "\n",
    "temp = merge_dictionaries(UK2017, UK2018)\n",
    "temp = merge_dictionaries(temp, UK2019)\n",
    "temp = merge_dictionaries(temp, UK2020)\n",
    "temp = merge_dictionaries(temp, UK2021)\n",
    "\n",
    "with open('processed data/UK_2017-2021.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(temp, f, ensure_ascii=False, indent=4)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "183bbf6827d058c2a2fb0f4acdc0420849dda2b4380af0e437e38c64d798d8b7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
