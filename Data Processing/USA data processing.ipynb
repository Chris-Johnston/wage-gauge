{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "def filterOccupations(df, descriptionColumn, SOCColumn, medianColumn, meanColumn):\n",
    "    \"\"\"\n",
    "    US wage data is cute. I love her. Didn't even need to open them up on excel to delete headers and footers because I'm too lazy to select ranges in python :) \n",
    "    Each row is tagged with an SOC group value (broad, major, minor, detailed)\n",
    "    I'm going to filter out broad categories.\n",
    "    If there are duplicate titles, I'm going to select the finest SOC group (major > minor > detailed).\n",
    "    Then I return a simplified dataframe with the following contents\n",
    "\n",
    "    Description   |   Median  |   Mean    |\n",
    "    ---------------------------------------\n",
    "    JobA          |    wage   |   wage    |\n",
    "    JobB          |    wage   |   wage    |\n",
    "    ...           |    ...    |   ...     |\n",
    "    JobZ          |    wage   |   wage    |\n",
    "\n",
    "    \"\"\"    \n",
    "    # filter out commas\n",
    "    df = df.replace(',','', regex = True)\n",
    "    df = df.replace('*',np.NaN)\n",
    "    df = df.replace('#',np.NaN)\n",
    "\n",
    "    # filter for optimal granularity and remove duplicates\n",
    "    df = df[df[SOCColumn] != 'broad'].reset_index(drop=True)\n",
    "    df['duplicates'] = df.duplicated(subset=descriptionColumn, keep='last') # because the data sets go through SOC groups with increasing granularity, we only want to keep the last duplicate if present\n",
    "    df = df[~df['duplicates']].reset_index(drop=True) # removes all duplicates that aren't of the finest SOC group\n",
    "\n",
    "    # convert to ideal datatypes\n",
    "    df[medianColumn] = round(df[medianColumn].astype('float64'),2)\n",
    "    df[meanColumn] = round(df[meanColumn].astype('float64'),2)\n",
    "\n",
    "    # filter out any rows where median & mean are null\n",
    "    df = df.dropna(axis=0, how='all', subset=[medianColumn,meanColumn]).reset_index(drop=True)\n",
    "\n",
    "    # select only columns of interest\n",
    "    df = df[[descriptionColumn, medianColumn, meanColumn]] \n",
    "\n",
    "    # rename columns for consistency with other data sets\n",
    "    df.columns = ['Description', 'Median', 'Mean']\n",
    "    return df\n",
    "\n",
    "def jsonifyOccupations(df, yearInput):\n",
    "    \"\"\"\n",
    "    Given a dataframe of occupations with mean | median salary data for a given year, write a dictionary string with the following format:\n",
    "    Yeah, there's probably a way to do this with a pandas grouping or pivot but I hate pandas.\n",
    "    {\n",
    "        'jobA': {\n",
    "            'year_1': {\n",
    "                'median': 0000000,\n",
    "                'mean': 0000000\n",
    "            }\n",
    "        },\n",
    "        \n",
    "        'jobB': {\n",
    "            'year_1': {\n",
    "                'median': 0000000,\n",
    "                'mean': 0000000\n",
    "            }\n",
    "        },\n",
    "        ...\n",
    "        \n",
    "        'jobZ': {\n",
    "            'year_1': {\n",
    "                'median': 0000000,\n",
    "                'mean': 0000000\n",
    "            }\n",
    "        }\n",
    "        \n",
    "    }\n",
    "    \"\"\"\n",
    "    d = dict.fromkeys(df.loc[:,'Description'])\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        d[df.loc[i,'Description']] = {}\n",
    "        content = dict.fromkeys(['median', 'mean'])\n",
    "        content['median'] = df.loc[i,'Median']\n",
    "        content['mean'] = df.loc[i,'Mean']\n",
    "        d[df.loc[i,'Description']][str(yearInput)] = content\n",
    "    return d\n",
    "\n",
    "def merge_dictionaries(dictA, dictB):\n",
    "    \"\"\"\n",
    "    Bruh does this function already exist wtf. This sounds like a homework problem but anyway\n",
    "    Take dictB. \n",
    "    If a key in dictB is present in dictA, append the contents of the key to dictA[key] (technically, i'm creating a new key with the year from dict B and assigning it's items).\n",
    "    Otherwise, add dictB[key] and it's contents as a new value in dictA.\n",
    "    \"\"\"\n",
    "    for key in dictB:\n",
    "        if key in dictA.keys():\n",
    "            dictA[key][list(dictB[key].keys())[0]] = list(dictB[key].values())[0]\n",
    "        else:\n",
    "            dictA[key] = dictB[key]\n",
    "    return dictA\n",
    "\n",
    "US2017 = jsonifyOccupations(filterOccupations(pd.read_csv('raw data/US 2017.csv'),'OCC_TITLE', 'OCC_GROUP', 'A_MEDIAN','A_MEAN'), 2017)\n",
    "US2018 = jsonifyOccupations(filterOccupations(pd.read_csv('raw data/US 2018.csv'),'OCC_TITLE', 'OCC_GROUP', 'A_MEDIAN','A_MEAN'), 2018)\n",
    "US2019 = jsonifyOccupations(filterOccupations(pd.read_csv('raw data/US 2019.csv'),'occ_title', 'o_group', 'a_median','a_mean'), 2019)\n",
    "US2020 = jsonifyOccupations(filterOccupations(pd.read_csv('raw data/US 2020.csv'),'OCC_TITLE', 'O_GROUP', 'A_MEDIAN','A_MEAN'), 2020)\n",
    "US2021 = jsonifyOccupations(filterOccupations(pd.read_csv('raw data/US 2021.csv'),'OCC_TITLE', 'O_GROUP', 'A_MEDIAN','A_MEAN'), 2021)\n",
    "\n",
    "temp = merge_dictionaries(US2017, US2018)\n",
    "temp = merge_dictionaries(temp, US2019)\n",
    "temp = merge_dictionaries(temp, US2020)\n",
    "temp = merge_dictionaries(temp, US2021)\n",
    "\n",
    "with open('processed data/US_2017-2021.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(temp, f, ensure_ascii=False, indent=4)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "183bbf6827d058c2a2fb0f4acdc0420849dda2b4380af0e437e38c64d798d8b7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
